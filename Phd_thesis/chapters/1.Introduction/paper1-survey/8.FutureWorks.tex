\section{Open problems and future directions}
Monocular visual SLAM comprises a complex and heterogeneous algorithm. Decades of development of geometry-based solutions have led to a set of accurate and efficient algorithms that nowadays make geometry-based SLAM the de facto standard in robotics. The following section discusses a series of open problems and suggests future directions to bring deep learning-based implementations closer to becoming the new standard for SLAM.

\subsection{Training data}
\label{sec:futureworks:trainingdata}
When it comes to training models, the amount of data available can significantly impact accuracy and reproducibility. Data augmentation techniques are often used to feed more data to the networks. However, this can make the training process challenging to replicate. The reproducibility can be improved using standard data splits, as done with KITTI \cite{kittieigensplit}. Additionally, it is important to ensure unbiased data distributions to train more accurate models. This can be achieved by quantifying any biases and designing a data split that minimizes them.

\subsection{Towards generalizable models}
\label{sec:futureworks:generalizability}
Alleviating the biases in the data distribution using data augmentation techniques has proven to improve generalizability in models in the literature. However, the next step towards achieving even greater results is the development of architectures that can learn in higher dimensions.
Pose regression modules often rely on classification networks with a shift-equivariant inductive bias. To make models more generalizable, one potential future work is the implementation of networks with higher-dimensional inductive biases. Section \ref{sec:deeplearning} presents a set of networks that meet this requirement.
GNNs, for example, have already been successfully integrated into end-to-end loop detection (see Section \ref{sec:deeplearning:loop}), showing potential for being integrated into other modules of the SLAM's architecture. 
Additionally, another important aspect of generalization is accounting for the camera's intrinsic parameters. By doing so, models can better account for a wider range of setups and include more data from different sources during training, thus improving the overall data's distribution.

\subsection{Closing the loop: computational expense}
It is well known that visual SLAM challenges the computer's computational power where it is leveraged. In geometry-based SLAM, the optimization from the front-end and the back-end, and the loop search from the loop detection algorithm, are three demanding algorithms that run simultaneously.
Deep learning implementations measure the progress of these algorithms in terms of accuracy, with less focus on computational expense. Thus, executing them within a complete SLAM pipeline is often unsuitable, one of the main open problems in deep learning-based SLAM. Geometry-based pipelines have proved that trading off the accuracy on the front-end with lower computational expense, in the end, leverages better results by allowing the optimization of the estimates in the back-end. Similarly, this realization could be imported into deep learning pipelines, integrating less accurate and computationally expensive models with a SLAM back-end. One way to face this could be by leveraging a pose graph optimization process that merely optimizes the poses and closes loops, as introduced in Section \ref{sec:backend:loopclosingandgraphopt}. Another way is to leverage a bundle adjustment algorithm. This brings up other challenges: integrating the model's latent space and output estimates into a graph and designing a cost function for optimizing them.

\subsection{From end-to-end front-end to end-to-end SLAM}
An alternative direction to the one presented before would be the development of a complete architecture for SLAM in an end-to-end fashion. Section \ref{sec:deeplearning:endSLAM} presents some preliminary works in this area. One deep learning architecture that exhibits promise for this direction is \acp{GNN}. GNNs are capable of leveraging inductive bias in higher dimensions,  and they enable the integration of heterogeneous data such as images and poses. Furthermore, exploiting the graph's sparsity brings the potential for computationally efficient models.

\subsection{Not just visual: model flexibility}
This survey primarily addresses monocular visual SLAM methods, but it is important to mention that geometry-based frameworks have the potential to incorporate other sensor measurements. By combining external measurements with the graph, these frameworks can produce better estimates from both data sources. However, integrating external measurements into deep learning pipelines is more challenging. One possible future direction is exploring the development of architectures that can handle a broader range of data sources.

\subsection{Reliability}
Challenging imaging conditions lead geometry-based algorithms to lose track and deep learning-based algorithms to retrieve spurious estimates. Reliable algorithms must be able to assess and handle the occurrence of such events.
In geometry-based SLAM, a loss of tracking can be readily identified by the inability to make an estimate owing to inconsistent or inadequate data. Conversely, deep learning models always retrieve an estimate.
Thus, an emerging field of study for deep learning networks is incorporating an uncertainty estimate into the output.
\section{Conclusions and future work}
\label{sec:futurework}
This chapter aims to provide an overview of monocular visual SLAM, formulating the different classes into which it is categorized according to its taxonomy and the algorithms that comprise it. First, geometry-based SLAM algorithms are presented to constitute the front and back-end. Later, deep learning pipelines are elaborated, which have led to the development of end-to-end methods. We believe the deep learning-based end-to-end SLAM algorithms set up a new paradigm for traditional SLAM.

Geometry-based monocular SLAM presents a well-established solution in terms of significant efficiency. The experiments showcase its known limitations: track failure and drift under visually or geometrically degraded scenes. Deep learning models tackle those limitations with higher-level representations of the environment, but the training environments limit their performance.
This limitation is mainly addressed by feeding more and more varied data to the network. However, considering the wide variety of deployment conditions, it is - for most of the applications - likely insufficient. It is then desired to achieve generalizability from the network's design side and not just from the data fed to it. Recently, studies on the underlying geometry under deep network architectures have arisen. The main findings through the comparison tests in this review for deep learning-based SLAM show that applying  geometric deep learning
pipelines remains still an open problem. This, together with the advances in fully-differentiable frameworks, and the study of continuous presentations for SLAM, presents promising lines of development that can meet a compromise between geometry and learning-based pipelines.